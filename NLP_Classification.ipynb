{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP to filter Email Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting and Random Forest with hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197.287741</td>\n",
       "      <td>0.128850</td>\n",
       "      <td>0.970806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.951974</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186.114172</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.970806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 16, 'n_est...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.286069</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.508479</td>\n",
       "      <td>0.124434</td>\n",
       "      <td>0.969234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.293444</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.955811</td>\n",
       "      <td>0.068211</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 16, 'n_est...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.807135</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1     197.287741         0.128850         0.970806               1.0   \n",
       "3     186.114172         0.077592         0.970806               1.0   \n",
       "0     103.508479         0.124434         0.969234               1.0   \n",
       "2      99.955811         0.068211         0.967213               1.0   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "1                 0.1               8                128   \n",
       "3                 0.1              16                128   \n",
       "0                 0.1               8                 64   \n",
       "2                 0.1              16                 64   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "1  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...                1   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 16, 'n_est...                1   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...                3   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 16, 'n_est...                4   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "1           0.968610       ...                  0.975281                 1.0   \n",
       "3           0.967489       ...                  0.975281                 1.0   \n",
       "0           0.966368       ...                  0.975281                 1.0   \n",
       "2           0.964126       ...                  0.970787                 1.0   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "1           0.974157                 1.0           0.977528   \n",
       "3           0.975281                 1.0           0.975281   \n",
       "0           0.970787                 1.0           0.974157   \n",
       "2           0.973034                 1.0           0.973034   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "1                 1.0      2.951974        0.034014        0.006832   \n",
       "3                 1.0      6.286069        0.002554        0.005880   \n",
       "0                 1.0      5.293444        0.003512        0.005733   \n",
       "2                 1.0      1.807135        0.002648        0.006880   \n",
       "\n",
       "   std_train_score  \n",
       "1              0.0  \n",
       "3              0.0  \n",
       "0              0.0  \n",
       "2              0.0  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting with cross validation and hyper parameter tuning \n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [64, 128], \n",
    "    'max_depth': [8, 16],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "clf = GridSearchCV(gb, param, cv=5, return_train_score=True)\n",
    "cv_fit = clf.fit(X_train_vect, y_train)\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.436447</td>\n",
       "      <td>0.137318</td>\n",
       "      <td>0.975971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 128}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298857</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.985330</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>0.996463</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 32}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.971973</td>\n",
       "      <td>0.997473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>0.997193</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.996913</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.995229</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.000915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.890204</td>\n",
       "      <td>0.161897</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 64}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.132754</td>\n",
       "      <td>0.128070</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.804828</td>\n",
       "      <td>0.116635</td>\n",
       "      <td>0.973950</td>\n",
       "      <td>0.996744</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 128}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.996349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.997193</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.141779</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.557841</td>\n",
       "      <td>0.076369</td>\n",
       "      <td>0.973726</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 64}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.976404</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.130704</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "8      13.436447         0.137318         0.975971          1.000000   \n",
       "3       2.985330         0.056478         0.975522          0.996463   \n",
       "7       8.890204         0.161897         0.975522          0.999944   \n",
       "5      10.804828         0.116635         0.973950          0.996744   \n",
       "4       5.557841         0.076369         0.973726          0.996800   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "8            None                128   \n",
       "3              64                 32   \n",
       "7            None                 64   \n",
       "5              64                128   \n",
       "4              64                 64   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "8  {'max_depth': None, 'n_estimators': 128}                1   \n",
       "3     {'max_depth': 64, 'n_estimators': 32}                2   \n",
       "7   {'max_depth': None, 'n_estimators': 64}                2   \n",
       "5    {'max_depth': 64, 'n_estimators': 128}                4   \n",
       "4     {'max_depth': 64, 'n_estimators': 64}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "8           0.973094            1.000000       ...                  0.975281   \n",
       "3           0.971973            0.997473       ...                  0.978652   \n",
       "7           0.967489            1.000000       ...                  0.974157   \n",
       "5           0.970852            0.996349       ...                  0.973034   \n",
       "4           0.970852            0.997192       ...                  0.975281   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "8            1.000000           0.982022            1.000000   \n",
       "3            0.997193           0.977528            0.996913   \n",
       "7            1.000000           0.983146            1.000000   \n",
       "5            0.997193           0.978652            0.997474   \n",
       "4            0.997474           0.977528            0.996071   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "8           0.979775            1.000000      0.298857        0.029130   \n",
       "3           0.979775            0.995229      0.107937        0.008302   \n",
       "7           0.978652            1.000000      3.132754        0.128070   \n",
       "5           0.978652            0.996071      0.141779        0.008199   \n",
       "4           0.976404            0.996071      0.130704        0.003468   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "8        0.004454         0.000000  \n",
       "3        0.003961         0.000915  \n",
       "7        0.005218         0.000112  \n",
       "5        0.004088         0.000521  \n",
       "4        0.003431         0.000604  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with cross validation and hyper parameter tuning\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [32, 64, 128],\n",
    "        'max_depth': [32, 64, None]}\n",
    "gs = GridSearchCV(rf, param, cv=5, return_train_score=True)\n",
    "gs_fit = gs.fit(X_train_vect, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting best parameters and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.992 / Recall: 0.807 / Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with best parameters (TF_IDF)\n",
    "rf = RandomForestClassifier(n_estimators=128, max_depth=None)\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label= 1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.823 / Accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with best parameters (Count Vectorization)\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None)\n",
    "rf_model = rf.fit(X_cvfTrain_vect, y1_train)\n",
    "y_pred = rf_model.predict(X_cvfTest_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y1_test, y_pred, pos_label= 1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.952 / Recall: 0.793 / Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting with best parameters (TF_IDF)\n",
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.977 / Recall: 0.887 / Accuracy: 0.785\n"
     ]
    }
   ],
   "source": [
    "# GB with best parameters (count vectorization)\n",
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "gb_model = gb.fit(X_cvfTrain_vect, y1_train)\n",
    "y_pred = gb_model.predict(X_cvfTest_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y1_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3562 samples, validate on 891 samples\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 5s 1ms/step - loss: 0.3056 - acc: 0.8782 - val_loss: 0.1360 - val_acc: 0.9686\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 3s 949us/step - loss: 0.0537 - acc: 0.9891 - val_loss: 0.0461 - val_acc: 0.9854\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 3s 848us/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0442 - val_acc: 0.9843\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 3s 811us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0487 - val_acc: 0.9854\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 3s 821us/step - loss: 6.4491e-04 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9843\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 3s 837us/step - loss: 4.1037e-04 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9854\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 3s 824us/step - loss: 2.1638e-04 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9854\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 3s 876us/step - loss: 1.3938e-04 - acc: 1.0000 - val_loss: 0.0525 - val_acc: 0.9843\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 3s 823us/step - loss: 1.1832e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9843\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 3s 832us/step - loss: 8.5295e-05 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9843\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 3s 820us/step - loss: 7.3792e-05 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 0.9843\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 3s 834us/step - loss: 6.0188e-05 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9843\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 3s 915us/step - loss: 4.2123e-05 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9854\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 3s 973us/step - loss: 3.9872e-05 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9854\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 4s 1ms/step - loss: 4.4779e-05 - acc: 1.0000 - val_loss: 0.0569 - val_acc: 0.9865\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 3s 923us/step - loss: 3.5722e-05 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 0.9865\n",
      "1114/1114 [==============================] - 0s 290us/step\n",
      "1114/1114 [==============================] - 1s 839us/step\n",
      "Precision: 0.948 / Recall: 0.853 / Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "# initialization of sequential object\n",
    "classifier = Sequential()\n",
    "# hidden layers\n",
    "classifier.add(Dense(units = 128,activation = 'relu',input_dim = X_train_vect.shape[1], name=\"input\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128,activation = 'relu', name=\"HLayer_1\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid',name = \"output\"))\n",
    "# compiling NN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "# Tensor Board Logs\n",
    "tblogs = TensorBoard(log_dir= './NlpAna', histogram_freq= 0, write_graph= True, write_images= True)\n",
    "model = classifier.fit(X_train_vect, y_train, batch_size = 32, callbacks = [tblogs], epochs = 16, verbose=1, shuffle= True, validation_split = 0.2)\n",
    "classifier.save(\"NLP_model.h5\")\n",
    "\n",
    "#model evaluation\n",
    "classifier.evaluate(X_test_vect, y_test)\n",
    "y_test= y_test.reshape(-1,1)\n",
    "y_pred = classifier.predict(X_test_vect, verbose = 1)\n",
    "y_pred = y_pred>0.6\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, average = 'binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN - Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 849us/step - loss: 0.3126 - acc: 0.8725\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 3s 752us/step - loss: 0.0563 - acc: 0.9896\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 3s 779us/step - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 3s 774us/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 741us/step - loss: 7.4246e-04 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 3s 775us/step - loss: 5.8678e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 3s 753us/step - loss: 2.6798e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 3s 923us/step - loss: 1.8020e-04 - acc: 1.0000 0s - loss: 1.9017e\n",
      "891/891 [==============================] - 0s 333us/step\n",
      "3562/3562 [==============================] - 1s 267us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 4s 1ms/step - loss: 0.3122 - acc: 0.8681\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 3s 866us/step - loss: 0.0558 - acc: 0.9891\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 3s 861us/step - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 3s 821us/step - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 937us/step - loss: 6.2646e-04 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 3s 937us/step - loss: 4.1544e-04 - acc: 1.0000 0s - loss: 4.46\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 3s 806us/step - loss: 2.9677e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 3s 821us/step - loss: 1.9258e-04 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 450us/step\n",
      "3562/3562 [==============================] - 1s 253us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 4s 1ms/step - loss: 0.3081 - acc: 0.8678\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 3s 872us/step - loss: 0.0554 - acc: 0.9896\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 3s 783us/step - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 3s 901us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 848us/step - loss: 4.8583e-04 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 3s 873us/step - loss: 3.3640e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 3s 841us/step - loss: 1.6380e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 3s 819us/step - loss: 1.2491e-04 - acc: 1.0000 0s - loss: 1.2642e-04 - acc: 1.00\n",
      "891/891 [==============================] - 0s 388us/step\n",
      "3562/3562 [==============================] - 1s 256us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 910us/step - loss: 0.3072 - acc: 0.8720\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 3s 851us/step - loss: 0.0639 - acc: 0.9882\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 3s 960us/step - loss: 0.0089 - acc: 0.9975 1s - loss: 0.0078 \n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 3s 828us/step - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 3s 827us/step - loss: 7.8139e-04 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 3s 848us/step - loss: 4.9379e-04 - acc: 1.0000 0s - loss: 5.1046e-04 \n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 3s 803us/step - loss: 3.8732e-04 - acc: 1.0000 2s -\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 3s 806us/step - loss: 1.6305e-04 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 387us/step\n",
      "3563/3563 [==============================] - 1s 206us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 891us/step - loss: 0.3128 - acc: 0.8720 1s - loss: 0.388\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 3s 791us/step - loss: 0.0571 - acc: 0.9877\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 3s 793us/step - loss: 0.0074 - acc: 0.9983\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 3s 714us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 3s 785us/step - loss: 6.7315e-04 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 3s 914us/step - loss: 4.0893e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 3s 949us/step - loss: 4.4476e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 3s 976us/step - loss: 1.7328e-04 - acc: 1.0000 1s - loss: 1\n",
      "890/890 [==============================] - 0s 400us/step\n",
      "3563/3563 [==============================] - 1s 210us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 810us/step - loss: 0.2649 - acc: 0.8975\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 3s 720us/step - loss: 0.0526 - acc: 0.9879\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 3s 755us/step - loss: 0.0262 - acc: 0.9927\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 3s 746us/step - loss: 0.0151 - acc: 0.9964 \n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 755us/step - loss: 0.0101 - acc: 0.9975\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 3s 779us/step - loss: 0.0067 - acc: 0.9986\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 3s 756us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 686us/step - loss: 0.0031 - acc: 0.9992\n",
      "891/891 [==============================] - 0s 370us/step\n",
      "3562/3562 [==============================] - 1s 201us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 745us/step - loss: 0.2594 - acc: 0.8975\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 653us/step - loss: 0.0499 - acc: 0.9862\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 697us/step - loss: 0.0216 - acc: 0.9941\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 3s 785us/step - loss: 0.0130 - acc: 0.9964 1s - los\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 719us/step - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 2s 644us/step - loss: 0.0050 - acc: 0.9986\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 651us/step - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 3s 742us/step - loss: 0.0017 - acc: 0.9994 0s - loss: 0.00\n",
      "891/891 [==============================] - 0s 459us/step\n",
      "3562/3562 [==============================] - 1s 219us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 809us/step - loss: 0.2796 - acc: 0.8944\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 680us/step - loss: 0.0527 - acc: 0.9876\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 3s 761us/step - loss: 0.0230 - acc: 0.9924\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 638us/step - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 3s 722us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 3s 740us/step - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 700us/step - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 688us/step - loss: 0.0014 - acc: 0.9994\n",
      "891/891 [==============================] - 0s 390us/step\n",
      "3562/3562 [==============================] - 1s 224us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 869us/step - loss: 0.2456 - acc: 0.9060\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 2s 653us/step - loss: 0.0533 - acc: 0.9851\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 631us/step - loss: 0.0254 - acc: 0.9930\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 2s 614us/step - loss: 0.0137 - acc: 0.9969\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 2s 658us/step - loss: 0.0099 - acc: 0.9978\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 2s 654us/step - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 3s 732us/step - loss: 0.0027 - acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 3s 740us/step - loss: 0.0013 - acc: 0.9994\n",
      "890/890 [==============================] - 0s 381us/step\n",
      "3563/3563 [==============================] - 1s 222us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 910us/step - loss: 0.2592 - acc: 0.9004\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 3s 707us/step - loss: 0.0527 - acc: 0.9854\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 691us/step - loss: 0.0237 - acc: 0.9913\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 3s 794us/step - loss: 0.0130 - acc: 0.9947\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 3s 760us/step - loss: 0.0080 - acc: 0.9966\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 3s 770us/step - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 2s 658us/step - loss: 0.0028 - acc: 0.9994 1s - loss: 0.\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 3s 772us/step - loss: 0.0021 - acc: 0.9997\n",
      "890/890 [==============================] - 0s 466us/step\n",
      "3563/3563 [==============================] - 1s 210us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 966us/step - loss: 0.3268 - acc: 0.8689\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 3s 881us/step - loss: 0.0551 - acc: 0.9885\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 3s 767us/step - loss: 0.0086 - acc: 0.9986\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 3s 722us/step - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 3s 725us/step - loss: 8.4605e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 3s 806us/step - loss: 4.5493e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 3s 828us/step - loss: 3.6823e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 3s 797us/step - loss: 1.6077e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 3s 731us/step - loss: 1.6490e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 3s 862us/step - loss: 1.2496e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 3s 725us/step - loss: 8.9731e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 3s 754us/step - loss: 1.0900e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 3s 812us/step - loss: 6.7413e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 3s 777us/step - loss: 5.0962e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 3s 821us/step - loss: 3.6484e-05 - acc: 1.0000 0s - loss: 3.6615e-05 - acc: 1.\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 3s 897us/step - loss: 3.4478e-05 - acc: 1.0000 1s - loss: 3.8185e-05 - acc: 1 - ETA: 1s - loss: 3.5529\n",
      "891/891 [==============================] - 0s 503us/step\n",
      "3562/3562 [==============================] - 1s 232us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 4s 1ms/step - loss: 0.3070 - acc: 0.8779\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 3s 846us/step - loss: 0.0466 - acc: 0.9907\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 3s 788us/step - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 3s 861us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 3s 761us/step - loss: 4.3990e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 3s 897us/step - loss: 3.3570e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 3s 930us/step - loss: 3.5059e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 3s 846us/step - loss: 2.0144e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 3s 828us/step - loss: 9.9893e-05 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 3s 764us/step - loss: 9.2552e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 3s 866us/step - loss: 7.3147e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 3s 847us/step - loss: 6.8923e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 3s 778us/step - loss: 4.0811e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 3s 739us/step - loss: 3.3786e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 3s 718us/step - loss: 3.5705e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 3s 906us/step - loss: 3.0795e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 470us/step\n",
      "3562/3562 [==============================] - 1s 224us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 4s 1ms/step - loss: 0.3198 - acc: 0.8695\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 3s 703us/step - loss: 0.0480 - acc: 0.9885\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 3s 746us/step - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 3s 733us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 3s 718us/step - loss: 5.8255e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 3s 730us/step - loss: 3.5598e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 3s 757us/step - loss: 1.9610e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 3s 707us/step - loss: 1.3821e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 700us/step - loss: 9.7649e-05 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 3s 711us/step - loss: 7.6586e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 3s 709us/step - loss: 7.3649e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 3s 728us/step - loss: 4.2460e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 3s 759us/step - loss: 4.1926e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 3s 712us/step - loss: 3.1509e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 3s 716us/step - loss: 4.2082e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 3s 710us/step - loss: 3.4452e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 437us/step\n",
      "3562/3562 [==============================] - 1s 209us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 928us/step - loss: 0.3149 - acc: 0.8748\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 3s 782us/step - loss: 0.0526 - acc: 0.9888\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 3s 743us/step - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 3s 722us/step - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 3s 722us/step - loss: 9.4996e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 3s 718us/step - loss: 3.7938e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 3s 734us/step - loss: 2.3491e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 3s 779us/step - loss: 1.2977e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 3s 749us/step - loss: 9.5165e-05 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 3s 731us/step - loss: 9.6460e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 3s 723us/step - loss: 5.8160e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 3s 725us/step - loss: 4.9806e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 3s 732us/step - loss: 4.0804e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 3s 783us/step - loss: 4.0571e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 3s 761us/step - loss: 2.8138e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 3s 757us/step - loss: 3.8825e-05 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 510us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3563/3563 [==============================] - 1s 208us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 934us/step - loss: 0.3207 - acc: 0.8684\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 3s 711us/step - loss: 0.0578 - acc: 0.9865\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 3s 782us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 3s 900us/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 3s 738us/step - loss: 4.8843e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 3s 778us/step - loss: 3.1707e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 3s 880us/step - loss: 2.3074e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 3s 918us/step - loss: 1.4921e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 3s 961us/step - loss: 1.3574e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 3s 837us/step - loss: 9.3112e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 3s 895us/step - loss: 5.5107e-05 - acc: 1.0000 2s -\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 699us/step - loss: 4.3569e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 3s 757us/step - loss: 4.4092e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 3s 758us/step - loss: 3.9485e-05 - acc: 1.0000 1s - loss: 3.5\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 695us/step - loss: 2.9302e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 2s 674us/step - loss: 2.7024e-05 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 461us/step\n",
      "3563/3563 [==============================] - 1s 219us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 785us/step - loss: 0.2708 - acc: 0.8897\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 685us/step - loss: 0.0622 - acc: 0.9854\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 702us/step - loss: 0.0273 - acc: 0.9921 0s - loss: 0.0249 - ac\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 3s 748us/step - loss: 0.0169 - acc: 0.9955\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 653us/step - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 609us/step - loss: 0.0068 - acc: 0.9983 0s - loss: 0.0074 - acc: 0.\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 594us/step - loss: 0.0049 - acc: 0.9989\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 615us/step - loss: 0.0036 - acc: 0.9989\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 659us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 3s 897us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 661us/step - loss: 7.8872e-04 - acc: 0.9994\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 584us/step - loss: 2.3292e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 587us/step - loss: 2.8827e-04 - acc: 0.9997\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 599us/step - loss: 3.3379e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 584us/step - loss: 2.2520e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 595us/step - loss: 1.8806e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 461us/step\n",
      "3562/3562 [==============================] - 1s 194us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 879us/step - loss: 0.2568 - acc: 0.9034\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 651us/step - loss: 0.0484 - acc: 0.9865\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 619us/step - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 614us/step - loss: 0.0135 - acc: 0.9958 0s - loss: 0.0135 - acc: 0.995\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 615us/step - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 620us/step - loss: 0.0053 - acc: 0.9980\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 630us/step - loss: 0.0028 - acc: 0.9986\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 679us/step - loss: 0.0014 - acc: 0.9992\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 606us/step - loss: 4.6415e-04 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 610us/step - loss: 4.0225e-04 - acc: 0.9997\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 614us/step - loss: 8.2349e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 609us/step - loss: 7.4287e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 620us/step - loss: 2.0784e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 622us/step - loss: 5.7595e-06 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 670us/step - loss: 9.6017e-07 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 623us/step - loss: 3.8324e-07 - acc: 1.0000 1s - loss: 3.152\n",
      "891/891 [==============================] - 0s 478us/step\n",
      "3562/3562 [==============================] - 1s 199us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 831us/step - loss: 0.2655 - acc: 0.8950\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 614us/step - loss: 0.0553 - acc: 0.9848\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 618us/step - loss: 0.0243 - acc: 0.9930\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 636us/step - loss: 0.0144 - acc: 0.9952\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 3s 721us/step - loss: 0.0091 - acc: 0.9978\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 615us/step - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 617us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 619us/step - loss: 0.0017 - acc: 0.9992\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 619us/step - loss: 4.8559e-04 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 629us/step - loss: 2.4481e-04 - acc: 1.0000 1s - lo\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 622us/step - loss: 9.2392e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 678us/step - loss: 3.0159e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 626us/step - loss: 9.0589e-06 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 616us/step - loss: 7.6913e-07 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 616us/step - loss: 3.1945e-07 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 620us/step - loss: 3.0063e-07 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 483us/step\n",
      "3562/3562 [==============================] - 1s 199us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 932us/step - loss: 0.2604 - acc: 0.8970\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 3s 743us/step - loss: 0.0546 - acc: 0.9860\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 696us/step - loss: 0.0250 - acc: 0.9924\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 2s 697us/step - loss: 0.0142 - acc: 0.9958 0s - loss: 0.0145 - acc: 0.\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 680us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 648us/step - loss: 0.0054 - acc: 0.9992\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 659us/step - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 3s 722us/step - loss: 7.5761e-04 - acc: 0.9997\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 3s 718us/step - loss: 4.6630e-04 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 643us/step - loss: 6.1502e-04 - acc: 0.9997\n",
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3563/3563 [==============================] - 2s 615us/step - loss: 2.3064e-04 - acc: 0.9997\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 609us/step - loss: 3.0870e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 2s 651us/step - loss: 3.7868e-06 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 2s 660us/step - loss: 1.8026e-06 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 686us/step - loss: 1.0943e-06 - acc: 1.0000 1s - loss: 9\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 2s 655us/step - loss: 5.8368e-07 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 520us/step\n",
      "3563/3563 [==============================] - 1s 222us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 798us/step - loss: 0.2548 - acc: 0.9029\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 2s 610us/step - loss: 0.0559 - acc: 0.9857\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 638us/step - loss: 0.0250 - acc: 0.9919\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 2s 637us/step - loss: 0.0142 - acc: 0.9958\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 691us/step - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 615us/step - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 585us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 2s 581us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 2s 588us/step - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 584us/step - loss: 4.9350e-04 - acc: 0.9997\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 2s 581us/step - loss: 6.2053e-04 - acc: 0.9997- loss: 0.\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 610us/step - loss: 3.9127e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 2s 642us/step - loss: 4.3313e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 2s 584us/step - loss: 3.5573e-06 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 607us/step - loss: 5.6354e-06 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 3s 714us/step - loss: 3.6889e-07 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 835us/step\n",
      "3563/3563 [==============================] - 1s 211us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 2s 678us/step - loss: 0.4368 - acc: 0.8495\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 496us/step - loss: 0.1425 - acc: 0.9220\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 540us/step - loss: 0.0326 - acc: 0.9938\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 520us/step - loss: 0.0076 - acc: 0.9989\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 466us/step - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 2s 600us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 464us/step - loss: 7.9249e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 459us/step - loss: 4.5959e-04 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 498us/step\n",
      "3562/3562 [==============================] - 1s 152us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 784us/step - loss: 0.4010 - acc: 0.8638\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 619us/step - loss: 0.1303 - acc: 0.9264\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 539us/step - loss: 0.0345 - acc: 0.9952\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 504us/step - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 520us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 2s 484us/step - loss: 9.3767e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 458us/step - loss: 6.4251e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 469us/step - loss: 4.0600e-04 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 497us/step\n",
      "3562/3562 [==============================] - 1s 145us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 2s 675us/step - loss: 0.4456 - acc: 0.8358\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 495us/step - loss: 0.1284 - acc: 0.9402\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 472us/step - loss: 0.0242 - acc: 0.9955\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 445us/step - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 442us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 2s 447us/step - loss: 8.3682e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 453us/step - loss: 4.7209e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 453us/step - loss: 3.4068e-04 - acc: 1.0000\n",
      "891/891 [==============================] - 0s 510us/step\n",
      "3562/3562 [==============================] - 1s 174us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 733us/step - loss: 0.3916 - acc: 0.8616\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 2s 516us/step - loss: 0.1289 - acc: 0.9357\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 505us/step - loss: 0.0351 - acc: 0.9947\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 2s 467us/step - loss: 0.0065 - acc: 0.9992 0s - loss: 0.0067 - acc\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 2s 446us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 2s 444us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 2s 451us/step - loss: 7.3255e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 2s 439us/step - loss: 4.9706e-04 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 527us/step\n",
      "3563/3563 [==============================] - 1s 152us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 727us/step - loss: 0.4145 - acc: 0.8591\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 2s 484us/step - loss: 0.1369 - acc: 0.9228\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 490us/step - loss: 0.0376 - acc: 0.9955\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 2s 460us/step - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 2s 436us/step - loss: 0.0022 - acc: 0.9997\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 2s 441us/step - loss: 9.5908e-04 - acc: 1.0000\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 2s 453us/step - loss: 6.4877e-04 - acc: 1.0000\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 2s 452us/step - loss: 3.5251e-04 - acc: 1.0000\n",
      "890/890 [==============================] - 0s 557us/step\n",
      "3563/3563 [==============================] - 1s 154us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 2s 678us/step - loss: 0.3247 - acc: 0.8770\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 1s 388us/step - loss: 0.0856 - acc: 0.9784\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 435us/step - loss: 0.0309 - acc: 0.9921\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 452us/step - loss: 0.0149 - acc: 0.9958\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 428us/step - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 1s 401us/step - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 1s 413us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 1s 397us/step - loss: 0.0017 - acc: 0.9992\n",
      "891/891 [==============================] - 0s 551us/step\n",
      "3562/3562 [==============================] - 1s 151us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 736us/step - loss: 0.3199 - acc: 0.8773\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 512us/step - loss: 0.0822 - acc: 0.9820\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3562/3562 [==============================] - 2s 576us/step - loss: 0.0254 - acc: 0.9938\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 556us/step - loss: 0.0130 - acc: 0.9964\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 594us/step - loss: 0.0078 - acc: 0.9972\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 1s 415us/step - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 560us/step - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 545us/step - loss: 0.0012 - acc: 0.9997\n",
      "891/891 [==============================] - 1s 775us/step\n",
      "3562/3562 [==============================] - 1s 202us/step\n",
      "Epoch 1/8\n",
      "3562/3562 [==============================] - 3s 845us/step - loss: 0.3161 - acc: 0.8798\n",
      "Epoch 2/8\n",
      "3562/3562 [==============================] - 2s 499us/step - loss: 0.0812 - acc: 0.9809\n",
      "Epoch 3/8\n",
      "3562/3562 [==============================] - 2s 477us/step - loss: 0.0279 - acc: 0.9927\n",
      "Epoch 4/8\n",
      "3562/3562 [==============================] - 2s 493us/step - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 5/8\n",
      "3562/3562 [==============================] - 2s 480us/step - loss: 0.0068 - acc: 0.9983\n",
      "Epoch 6/8\n",
      "3562/3562 [==============================] - 2s 436us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 7/8\n",
      "3562/3562 [==============================] - 2s 484us/step - loss: 0.0018 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3562/3562 [==============================] - 2s 512us/step - loss: 4.7232e-04 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 819us/step\n",
      "3562/3562 [==============================] - 1s 179us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 767us/step - loss: 0.3285 - acc: 0.8695\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 2s 498us/step - loss: 0.0838 - acc: 0.9795\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 466us/step - loss: 0.0296 - acc: 0.9921\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 2s 430us/step - loss: 0.0158 - acc: 0.9958\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 2s 438us/step - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 2s 438us/step - loss: 0.0047 - acc: 0.9986 0s - loss: 0.0041 - acc:\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 2s 432us/step - loss: 0.0018 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 2s 463us/step - loss: 6.1631e-04 - acc: 0.9997\n",
      "890/890 [==============================] - 1s 636us/step\n",
      "3563/3563 [==============================] - 1s 164us/step\n",
      "Epoch 1/8\n",
      "3563/3563 [==============================] - 3s 791us/step - loss: 0.3189 - acc: 0.8723\n",
      "Epoch 2/8\n",
      "3563/3563 [==============================] - 2s 508us/step - loss: 0.0954 - acc: 0.9761\n",
      "Epoch 3/8\n",
      "3563/3563 [==============================] - 2s 499us/step - loss: 0.0324 - acc: 0.9919\n",
      "Epoch 4/8\n",
      "3563/3563 [==============================] - 2s 440us/step - loss: 0.0142 - acc: 0.9952 0s - loss: 0.01\n",
      "Epoch 5/8\n",
      "3563/3563 [==============================] - 2s 446us/step - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 6/8\n",
      "3563/3563 [==============================] - 2s 444us/step - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 7/8\n",
      "3563/3563 [==============================] - 2s 443us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 8/8\n",
      "3563/3563 [==============================] - 2s 444us/step - loss: 5.7568e-04 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 629us/step\n",
      "3563/3563 [==============================] - 1s 168us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 823us/step - loss: 0.4096 - acc: 0.8591\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 551us/step - loss: 0.1299 - acc: 0.9354\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 540us/step - loss: 0.0327 - acc: 0.9944\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 500us/step - loss: 0.0079 - acc: 0.9980\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 478us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 492us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 507us/step - loss: 6.8136e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 505us/step - loss: 5.1906e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 503us/step - loss: 2.8870e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 584us/step - loss: 2.4286e-04 - acc: 1.0000 0s - loss: 2.4630e-04 - acc: 1\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 557us/step - loss: 1.6471e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 536us/step - loss: 1.3620e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 493us/step - loss: 1.3376e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 505us/step - loss: 1.0811e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 518us/step - loss: 9.9287e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 505us/step - loss: 7.8264e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 650us/step\n",
      "3562/3562 [==============================] - 1s 162us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 885us/step - loss: 0.3956 - acc: 0.8641\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 577us/step - loss: 0.1221 - acc: 0.9374\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 611us/step - loss: 0.0341 - acc: 0.9964\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 489us/step - loss: 0.0074 - acc: 0.9986 0s - loss: 0.0075 - acc: 0.99\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 546us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 476us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 522us/step - loss: 6.6766e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 526us/step - loss: 4.1230e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 519us/step - loss: 3.2131e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 499us/step - loss: 2.0856e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 488us/step - loss: 2.1465e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 445us/step - loss: 1.4562e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 475us/step - loss: 1.6439e-04 - acc: 1.0000 1s - loss: 1.6\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 455us/step - loss: 1.2319e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 439us/step - loss: 9.6933e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 476us/step - loss: 7.4221e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 658us/step\n",
      "3562/3562 [==============================] - 1s 152us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 782us/step - loss: 0.4158 - acc: 0.8537\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 493us/step - loss: 0.1383 - acc: 0.9253\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 511us/step - loss: 0.0362 - acc: 0.9944\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 477us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 484us/step - loss: 0.0019 - acc: 1.0000 1s - loss: 0.\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 2s 445us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 460us/step - loss: 6.5340e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 464us/step - loss: 3.9619e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 463us/step - loss: 2.6347e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 460us/step - loss: 2.0467e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 492us/step - loss: 1.8014e-04 - acc: 1.0000\n",
      "Epoch 12/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3562/3562 [==============================] - 2s 517us/step - loss: 1.4213e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 525us/step - loss: 1.2537e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 466us/step - loss: 8.3076e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 497us/step - loss: 9.3790e-05 - acc: 1.0000 1s - loss: 6.6195e-05 - acc: 1 - ETA: 0s - loss: 8.3002e-\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 471us/step - loss: 6.9024e-05 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 690us/step\n",
      "3562/3562 [==============================] - 1s 157us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 825us/step - loss: 0.4201 - acc: 0.8630\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 2s 463us/step - loss: 0.1329 - acc: 0.9296\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 505us/step - loss: 0.0369 - acc: 0.9941\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 2s 473us/step - loss: 0.0080 - acc: 0.9986\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 447us/step - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 445us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 446us/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 2s 442us/step - loss: 4.7322e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 2s 438us/step - loss: 3.3538e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 450us/step - loss: 2.5430e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 2s 451us/step - loss: 2.7874e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 461us/step - loss: 1.8198e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 2s 489us/step - loss: 1.2912e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 2s 474us/step - loss: 1.1233e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 451us/step - loss: 9.3419e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 2s 435us/step - loss: 7.2671e-05 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 674us/step\n",
      "3563/3563 [==============================] - 1s 154us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 806us/step - loss: 0.4114 - acc: 0.8625\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 2s 465us/step - loss: 0.1421 - acc: 0.9074\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 455us/step - loss: 0.0503 - acc: 0.9935\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 2s 453us/step - loss: 0.0083 - acc: 0.9986\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 542us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 494us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 459us/step - loss: 7.7540e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 2s 460us/step - loss: 6.3020e-04 - acc: 1.0000 1s - loss: 4.075\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 2s 453us/step - loss: 3.4245e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 438us/step - loss: 2.6134e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 2s 444us/step - loss: 2.0623e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 447us/step - loss: 1.6580e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 2s 443us/step - loss: 1.7688e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 2s 480us/step - loss: 1.3491e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 495us/step - loss: 1.0555e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 2s 464us/step - loss: 9.8180e-05 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 715us/step\n",
      "3563/3563 [==============================] - 1s 160us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 743us/step - loss: 0.3131 - acc: 0.8754\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 1s 413us/step - loss: 0.0838 - acc: 0.9795\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 1s 393us/step - loss: 0.0287 - acc: 0.9933\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 1s 403us/step - loss: 0.0146 - acc: 0.9964\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 1s 411us/step - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 1s 404us/step - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 2s 441us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 427us/step - loss: 0.0012 - acc: 0.9994\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 1s 421us/step - loss: 0.0010 - acc: 0.9994\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 1s 401us/step - loss: 7.0267e-04 - acc: 0.9994\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 1s 417us/step - loss: 3.7389e-04 - acc: 0.9997\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 2s 452us/step - loss: 6.1222e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 1s 392us/step - loss: 3.4011e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 423us/step - loss: 2.2734e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 1s 401us/step - loss: 4.0323e-06 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 442us/step - loss: 1.6760e-06 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 782us/step\n",
      "3562/3562 [==============================] - 1s 180us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 839us/step - loss: 0.3126 - acc: 0.8773\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 1s 404us/step - loss: 0.0856 - acc: 0.9792\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 1s 409us/step - loss: 0.0274 - acc: 0.9944\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 421us/step - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 1s 409us/step - loss: 0.0069 - acc: 0.9983\n",
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 1s 410us/step - loss: 0.0037 - acc: 0.9986\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 1s 405us/step - loss: 0.0025 - acc: 0.9994ETA: 1s - loss:\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 1s 409us/step - loss: 9.1149e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 1s 412us/step - loss: 4.1215e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 459us/step - loss: 1.2719e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 460us/step - loss: 9.4608e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 1s 396us/step - loss: 4.9387e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 1s 397us/step - loss: 1.5021e-05 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 1s 399us/step - loss: 1.5976e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 1s 396us/step - loss: 5.4853e-06 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 1s 401us/step - loss: 1.4047e-06 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 725us/step\n",
      "3562/3562 [==============================] - 1s 160us/step\n",
      "Epoch 1/16\n",
      "3562/3562 [==============================] - 3s 787us/step - loss: 0.3253 - acc: 0.8720\n",
      "Epoch 2/16\n",
      "3562/3562 [==============================] - 2s 424us/step - loss: 0.0871 - acc: 0.9792 1s - loss\n",
      "Epoch 3/16\n",
      "3562/3562 [==============================] - 2s 458us/step - loss: 0.0277 - acc: 0.9927 1s - los\n",
      "Epoch 4/16\n",
      "3562/3562 [==============================] - 2s 427us/step - loss: 0.0134 - acc: 0.9958\n",
      "Epoch 5/16\n",
      "3562/3562 [==============================] - 2s 456us/step - loss: 0.0067 - acc: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/16\n",
      "3562/3562 [==============================] - 1s 393us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 7/16\n",
      "3562/3562 [==============================] - 1s 402us/step - loss: 0.0015 - acc: 0.9994\n",
      "Epoch 8/16\n",
      "3562/3562 [==============================] - 2s 438us/step - loss: 3.0849e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3562/3562 [==============================] - 2s 434us/step - loss: 1.8976e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3562/3562 [==============================] - 2s 460us/step - loss: 2.7494e-05 - acc: 1.0000 0s - loss: 3.8388e-05\n",
      "Epoch 11/16\n",
      "3562/3562 [==============================] - 2s 442us/step - loss: 7.7475e-06 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3562/3562 [==============================] - 1s 415us/step - loss: 5.8387e-06 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3562/3562 [==============================] - 2s 479us/step - loss: 2.5541e-06 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3562/3562 [==============================] - 2s 468us/step - loss: 4.2765e-07 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3562/3562 [==============================] - 2s 434us/step - loss: 4.0994e-07 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3562/3562 [==============================] - 2s 452us/step - loss: 2.7601e-07 - acc: 1.0000\n",
      "891/891 [==============================] - 1s 758us/step\n",
      "3562/3562 [==============================] - 1s 165us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 840us/step - loss: 0.3263 - acc: 0.8745\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 2s 426us/step - loss: 0.0898 - acc: 0.9764\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 425us/step - loss: 0.0311 - acc: 0.9919\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 1s 417us/step - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 443us/step - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 463us/step - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 457us/step - loss: 0.0024 - acc: 0.9994: 0s - loss: 0.0026 - acc: 0.9\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 2s 435us/step - loss: 0.0013 - acc: 0.9994\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 2s 430us/step - loss: 5.1660e-04 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 436us/step - loss: 4.7209e-04 - acc: 0.9997\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 2s 428us/step - loss: 9.0677e-05 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 2s 426us/step - loss: 3.9823e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 2s 484us/step - loss: 9.8517e-06 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 2s 479us/step - loss: 7.7423e-06 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 2s 483us/step - loss: 1.2329e-06 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 2s 534us/step - loss: 2.1077e-06 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 959us/step\n",
      "3563/3563 [==============================] - 1s 162us/step\n",
      "Epoch 1/16\n",
      "3563/3563 [==============================] - 3s 982us/step - loss: 0.3126 - acc: 0.8765 8s - loss\n",
      "Epoch 2/16\n",
      "3563/3563 [==============================] - 1s 408us/step - loss: 0.0823 - acc: 0.9801\n",
      "Epoch 3/16\n",
      "3563/3563 [==============================] - 2s 423us/step - loss: 0.0299 - acc: 0.9919\n",
      "Epoch 4/16\n",
      "3563/3563 [==============================] - 2s 423us/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 5/16\n",
      "3563/3563 [==============================] - 2s 437us/step - loss: 0.0065 - acc: 0.9983 1s - loss: \n",
      "Epoch 6/16\n",
      "3563/3563 [==============================] - 2s 444us/step - loss: 0.0033 - acc: 0.9986\n",
      "Epoch 7/16\n",
      "3563/3563 [==============================] - 2s 544us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 8/16\n",
      "3563/3563 [==============================] - 2s 507us/step - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 9/16\n",
      "3563/3563 [==============================] - 2s 461us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 10/16\n",
      "3563/3563 [==============================] - 2s 438us/step - loss: 1.5056e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3563/3563 [==============================] - 1s 414us/step - loss: 1.4229e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3563/3563 [==============================] - 1s 416us/step - loss: 5.3726e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3563/3563 [==============================] - 1s 415us/step - loss: 8.2750e-06 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3563/3563 [==============================] - 1s 419us/step - loss: 2.7690e-06 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3563/3563 [==============================] - 1s 410us/step - loss: 2.1406e-06 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3563/3563 [==============================] - 1s 411us/step - loss: 6.9054e-07 - acc: 1.0000\n",
      "890/890 [==============================] - 1s 972us/step\n",
      "3563/3563 [==============================] - 1s 189us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 18.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4453/4453 [==============================] - 5s 1ms/step - loss: 0.2827 - acc: 0.8796\n",
      "Epoch 2/16\n",
      "4453/4453 [==============================] - 4s 801us/step - loss: 0.0502 - acc: 0.9897\n",
      "Epoch 3/16\n",
      "4453/4453 [==============================] - 4s 846us/step - loss: 0.0065 - acc: 0.9984\n",
      "Epoch 4/16\n",
      "4453/4453 [==============================] - 4s 870us/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 5/16\n",
      "4453/4453 [==============================] - 4s 814us/step - loss: 4.4414e-04 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "4453/4453 [==============================] - 4s 877us/step - loss: 3.3735e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "4453/4453 [==============================] - 4s 856us/step - loss: 1.4465e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "4453/4453 [==============================] - 4s 815us/step - loss: 1.5603e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "4453/4453 [==============================] - 4s 813us/step - loss: 7.8561e-05 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "4453/4453 [==============================] - 3s 765us/step - loss: 7.1593e-05 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "4453/4453 [==============================] - 4s 868us/step - loss: 4.3028e-05 - acc: 1.0000 0s - loss: 4.5260e-\n",
      "Epoch 12/16\n",
      "4453/4453 [==============================] - 4s 819us/step - loss: 5.1152e-05 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "4453/4453 [==============================] - 4s 822us/step - loss: 1.6548e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "4453/4453 [==============================] - 3s 757us/step - loss: 3.7695e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "4453/4453 [==============================] - 4s 872us/step - loss: 5.1165e-05 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "4453/4453 [==============================] - 3s 766us/step - loss: 2.2017e-05 - acc: 1.0000 1s - loss\n",
      "Best_parameters  {'batch_size': 32, 'epochs': 16, 'optimizer': 'adam'}\n",
      "Best_Score  0.986525937837883\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter tuning\n",
    "def build_class(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 128,activation = 'relu',input_dim = X_train_vect.shape[1], name=\"input\"))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(units = 128,activation = 'relu', name=\"HLayer_1\"))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid',name = \"output\"))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_class, batch_size = 64, epochs = 32)\n",
    "parameters = {'epochs': [8,16],\n",
    "              'batch_size': [32,64],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "gs = GridSearchCV(estimator = classifier, param_grid = parameters, cv = 5, verbose =1)\n",
    "gs_op = gs.fit(X_train_vect, y_train)\n",
    "print('Best_parameters ',(gs.best_params_))\n",
    "print('Best_Score ',(gs.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}